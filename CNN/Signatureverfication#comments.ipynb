{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdsIZFdSZnaU",
        "outputId": "ff6f5ea0-129a-468b-c448-a9ddbc904963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (210, 128, 128, 1), Testing set shape: (45, 128, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Set image dimensions and path\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128  # Standardize images to 128x128 dimensions\n",
        "DATA_PATH = '/content/drive/MyDrive/Signature'  # Directory containing signature images\n",
        "\n",
        "def load_images():\n",
        "    \"\"\"\n",
        "    Loads and preprocesses images from the specified dataset directory.\n",
        "\n",
        "    - Reads images from 'genuine' and 'forged' categories.\n",
        "    - Labels images as genuine (1) or forged (0) based on filename metadata.\n",
        "    - Normalizes image pixel values and reshapes for CNN compatibility.\n",
        "\n",
        "    Returns:\n",
        "        images (numpy array): Preprocessed images.\n",
        "        labels (numpy array): Corresponding labels.\n",
        "    \"\"\"\n",
        "    images, labels = [], []\n",
        "    for category in ['genuine', 'forged']:  # Loop through both categories\n",
        "        path = os.path.join(DATA_PATH, category)  # Construct category path\n",
        "        for filename in os.listdir(path):  # Iterate over image files in the category\n",
        "            # Extract owner ID and signer ID from the filename\n",
        "            id_owner = filename.split('-')[1][:3]  # First 3 digits of the second segment\n",
        "            id_signer = filename.split('-')[1][5:8]  # Digits 5-7 of the second segment\n",
        "\n",
        "            # Label the image as 1 (genuine) if owner ID matches signer ID, else 0\n",
        "            label = 1 if id_owner == id_signer else 0\n",
        "\n",
        "            # Read the image in grayscale mode\n",
        "            img = cv2.imread(os.path.join(path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            # Resize the image to standard dimensions\n",
        "            img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "            # Normalize pixel values to range [0, 1]\n",
        "            img = img / 255.0\n",
        "\n",
        "            images.append(img)  # Append preprocessed image to list\n",
        "            labels.append(label)  # Append corresponding label\n",
        "\n",
        "    # Convert image and label lists to numpy arrays\n",
        "    images = np.array(images).reshape(-1, IMG_HEIGHT, IMG_WIDTH, 1)  # Add channel dimension for CNN\n",
        "    labels = np.array(labels)  # Convert labels to numpy array\n",
        "    return images, labels\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "X, y = load_images()\n",
        "y = to_categorical(y, num_classes=2)  # Convert labels to one-hot encoding for classification\n",
        "\n",
        "# Split the dataset into training, testing, and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% training, 30% testing\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)  # Split test set equally into validation and testing\n",
        "\n",
        "# Print the shapes of the datasets to confirm successful splitting\n",
        "print(f\"Training set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "def build_model():\n",
        "    \"\"\"\n",
        "    Builds and compiles a Convolutional Neural Network (CNN) model for signature verification.\n",
        "\n",
        "    Model Architecture:\n",
        "    - Convolutional and MaxPooling layers for feature extraction.\n",
        "    - Dropout layers to reduce overfitting.\n",
        "    - Fully connected Dense layers for classification.\n",
        "    - Softmax activation for binary classification output.\n",
        "\n",
        "    Returns:\n",
        "        model (Sequential): Compiled CNN model.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # First convolutional block\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),  # 32 filters, 3x3 kernel\n",
        "        MaxPooling2D((2, 2)),  # Reduce spatial dimensions by half\n",
        "        Dropout(0.25),  # Prevent overfitting\n",
        "\n",
        "        # Second convolutional block\n",
        "        Conv2D(64, (3, 3), activation='relu'),  # 64 filters, 3x3 kernel\n",
        "        MaxPooling2D((2, 2)),  # Reduce spatial dimensions by half\n",
        "        Dropout(0.25),  # Prevent overfitting\n",
        "\n",
        "        # Third convolutional block\n",
        "        Conv2D(128, (3, 3), activation='relu'),  # 128 filters, 3x3 kernel\n",
        "        MaxPooling2D((2, 2)),  # Reduce spatial dimensions by half\n",
        "        Dropout(0.25),  # Prevent overfitting\n",
        "\n",
        "        # Fully connected layers\n",
        "        Flatten(),  # Flatten 3D feature maps to 1D feature vector\n",
        "        Dense(128, activation='relu'),  # Dense layer with 128 neurons\n",
        "        Dropout(0.5),  # Higher dropout for regularization\n",
        "        Dense(2, activation='softmax')  # Output layer with 2 neurons for binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model with Adam optimizer and categorical crossentropy loss\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build and summarize the CNN model\n",
        "model = build_model()\n",
        "model.summary()  # Print the model architecture\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "SZng1CxyZ_ia",
        "outputId": "61982991-4aa6-4691-bf3e-35d0635ab867"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,211,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m258\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,304,322\u001b[0m (12.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,322</span> (12.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,304,322\u001b[0m (12.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,304,322</span> (12.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of epochs and batch size for training\n",
        "EPOCHS = 45  # Number of complete passes through the training data\n",
        "BATCH_SIZE = 32  # Number of samples per batch during training\n",
        "\n",
        "# Train the CNN model\n",
        "history = model.fit(\n",
        "    X_train, y_train,            # Training data and corresponding labels\n",
        "    epochs=EPOCHS,               # Number of epochs to train\n",
        "    batch_size=BATCH_SIZE,       # Batch size for gradient updates\n",
        "    validation_data=(X_val, y_val),  # Validation data and labels for monitoring\n",
        "    verbose=1                    # Verbose output for training progress\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xiUUZ0paF0A",
        "outputId": "2eab31db-b7ee-4703-9702-29ff5a68034f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.4614 - loss: 0.9033 - val_accuracy: 0.3556 - val_loss: 0.6933\n",
            "Epoch 2/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 914ms/step - accuracy: 0.5077 - loss: 0.6945 - val_accuracy: 0.4222 - val_loss: 0.6945\n",
            "Epoch 3/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5364 - loss: 0.6914 - val_accuracy: 0.4222 - val_loss: 0.6940\n",
            "Epoch 4/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.6922 - val_accuracy: 0.4222 - val_loss: 0.6928\n",
            "Epoch 5/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.4629 - loss: 0.6943 - val_accuracy: 0.4444 - val_loss: 0.6913\n",
            "Epoch 6/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 897ms/step - accuracy: 0.5419 - loss: 0.6906 - val_accuracy: 0.4444 - val_loss: 0.6914\n",
            "Epoch 7/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 908ms/step - accuracy: 0.5301 - loss: 0.6889 - val_accuracy: 0.4444 - val_loss: 0.6897\n",
            "Epoch 8/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.5607 - loss: 0.6883 - val_accuracy: 0.4444 - val_loss: 0.6808\n",
            "Epoch 9/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.5067 - loss: 0.6803 - val_accuracy: 0.5111 - val_loss: 0.6661\n",
            "Epoch 10/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5353 - loss: 0.6622 - val_accuracy: 0.7111 - val_loss: 0.6295\n",
            "Epoch 11/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 1s/step - accuracy: 0.6237 - loss: 0.6277 - val_accuracy: 0.5556 - val_loss: 0.6048\n",
            "Epoch 12/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.6397 - loss: 0.5860 - val_accuracy: 0.7778 - val_loss: 0.5266\n",
            "Epoch 13/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 892ms/step - accuracy: 0.7448 - loss: 0.5369 - val_accuracy: 0.8000 - val_loss: 0.4669\n",
            "Epoch 14/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.7746 - loss: 0.4762 - val_accuracy: 0.7333 - val_loss: 0.4678\n",
            "Epoch 15/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6143 - loss: 0.6052 - val_accuracy: 0.7111 - val_loss: 0.5074\n",
            "Epoch 16/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 962ms/step - accuracy: 0.8113 - loss: 0.4626 - val_accuracy: 0.7111 - val_loss: 0.4477\n",
            "Epoch 17/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7485 - loss: 0.4792 - val_accuracy: 0.7333 - val_loss: 0.4487\n",
            "Epoch 18/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7709 - loss: 0.4362 - val_accuracy: 0.7111 - val_loss: 0.4453\n",
            "Epoch 19/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 886ms/step - accuracy: 0.8003 - loss: 0.3943 - val_accuracy: 0.6667 - val_loss: 0.4717\n",
            "Epoch 20/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.8382 - loss: 0.3610 - val_accuracy: 0.6667 - val_loss: 0.4938\n",
            "Epoch 21/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8370 - loss: 0.3524 - val_accuracy: 0.7333 - val_loss: 0.4861\n",
            "Epoch 22/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 959ms/step - accuracy: 0.8569 - loss: 0.3387 - val_accuracy: 0.7333 - val_loss: 0.6358\n",
            "Epoch 23/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8350 - loss: 0.3322 - val_accuracy: 0.7111 - val_loss: 0.4718\n",
            "Epoch 24/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 872ms/step - accuracy: 0.8831 - loss: 0.2557 - val_accuracy: 0.8000 - val_loss: 0.4578\n",
            "Epoch 25/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9004 - loss: 0.2584 - val_accuracy: 0.7778 - val_loss: 0.5026\n",
            "Epoch 26/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.8819 - loss: 0.2238 - val_accuracy: 0.7556 - val_loss: 0.4345\n",
            "Epoch 27/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9101 - loss: 0.2168 - val_accuracy: 0.8000 - val_loss: 0.3958\n",
            "Epoch 28/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9101 - loss: 0.1974 - val_accuracy: 0.7778 - val_loss: 0.5076\n",
            "Epoch 29/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9315 - loss: 0.2506 - val_accuracy: 0.8444 - val_loss: 0.5488\n",
            "Epoch 30/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 948ms/step - accuracy: 0.9275 - loss: 0.1644 - val_accuracy: 0.7556 - val_loss: 0.5978\n",
            "Epoch 31/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9088 - loss: 0.2330 - val_accuracy: 0.8222 - val_loss: 0.5440\n",
            "Epoch 32/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9400 - loss: 0.1610 - val_accuracy: 0.8444 - val_loss: 0.5725\n",
            "Epoch 33/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8979 - loss: 0.1754 - val_accuracy: 0.8667 - val_loss: 0.6801\n",
            "Epoch 34/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 901ms/step - accuracy: 0.9597 - loss: 0.1043 - val_accuracy: 0.8000 - val_loss: 0.4686\n",
            "Epoch 35/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9463 - loss: 0.1503 - val_accuracy: 0.8000 - val_loss: 0.4770\n",
            "Epoch 36/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 911ms/step - accuracy: 0.9828 - loss: 0.0922 - val_accuracy: 0.8222 - val_loss: 0.4890\n",
            "Epoch 37/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9650 - loss: 0.0983 - val_accuracy: 0.8222 - val_loss: 0.5533\n",
            "Epoch 38/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.9767 - loss: 0.0864 - val_accuracy: 0.7778 - val_loss: 0.6405\n",
            "Epoch 39/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 911ms/step - accuracy: 0.9691 - loss: 0.0784 - val_accuracy: 0.8000 - val_loss: 0.4366\n",
            "Epoch 40/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9897 - loss: 0.0533 - val_accuracy: 0.8667 - val_loss: 0.4804\n",
            "Epoch 41/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9723 - loss: 0.0583 - val_accuracy: 0.8667 - val_loss: 0.5906\n",
            "Epoch 42/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 880ms/step - accuracy: 0.9684 - loss: 0.0709 - val_accuracy: 0.8667 - val_loss: 0.5299\n",
            "Epoch 43/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.9891 - loss: 0.0563 - val_accuracy: 0.8444 - val_loss: 0.4239\n",
            "Epoch 44/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9759 - loss: 0.0955 - val_accuracy: 0.8444 - val_loss: 0.5070\n",
            "Epoch 45/45\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 902ms/step - accuracy: 0.9789 - loss: 0.0389 - val_accuracy: 0.8889 - val_loss: 0.6603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to a specified file path\n",
        "model.save('/content/drive/MyDrive/Dataset_CNN/Signature/Models/sign_45.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w2gXK5xdyGV",
        "outputId": "dc59103e-13d6-4ec6-d60c-dde9202650ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the testing dataset\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)  # Set verbose to 0 for silent output\n",
        "\n",
        "# Print the test accuracy and loss\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")  # Convert accuracy to percentage and format to 2 decimal places\n",
        "print(f\"Test Loss: {test_loss:.4f}\")  # Display loss formatted to 4 decimal places\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT6ct_bXd74t",
        "outputId": "07628b48-50d1-436e-826a-3ff0f2b09d24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.22%\n",
            "Test Loss: 0.6662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate predictions for the test data\n",
        "y_pred = model.predict(X_test)  # Get predicted probabilities for each class\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to predicted class labels\n",
        "y_true_classes = np.argmax(y_test, axis=1)  # Extract true class labels from one-hot encoded test labels\n",
        "\n",
        "# Print unique class values in true and predicted labels\n",
        "print(\"Unique values in y_true_classes:\", np.unique(y_true_classes))  # Display unique true class labels\n",
        "print(\"Unique values in y_pred_classes:\", np.unique(y_pred_classes))  # Display unique predicted class labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBce6xPYeo-9",
        "outputId": "93bb4df5-fe33-4e6e-fa61-9feb795ebaa7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step\n",
            "Unique values in y_true_classes: [0 1]\n",
            "Unique values in y_pred_classes: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)  # Get predicted probabilities\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to predicted class labels\n",
        "y_true_classes = np.argmax(y_test, axis=1)  # Convert one-hot encoded labels to class indices\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=[\"Forged\", \"Genuine\"]))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSOdUBlNery8",
        "outputId": "044da7ed-56be-4c77-a268-07c355ed4782"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Forged       0.94      0.70      0.80        23\n",
            "     Genuine       0.75      0.95      0.84        22\n",
            "\n",
            "    accuracy                           0.82        45\n",
            "   macro avg       0.85      0.83      0.82        45\n",
            "weighted avg       0.85      0.82      0.82        45\n",
            "\n",
            "Confusion Matrix:\n",
            " [[16  7]\n",
            " [ 1 21]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(file_path):\n",
        "    \"\"\"\n",
        "    Preprocesses an input image for prediction by the trained CNN model.\n",
        "\n",
        "    Steps:\n",
        "    - Reads the image in grayscale mode.\n",
        "    - Resizes the image to 128x128 dimensions to match the model input size.\n",
        "    - Normalizes pixel values to the range [0, 1].\n",
        "    - Reshapes the image to add batch and channel dimensions.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Preprocessed image ready for prediction.\n",
        "    \"\"\"\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
        "    img = cv2.resize(img, (128, 128))  # Resize to match training dimensions\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    img = img.reshape(1, 128, 128, 1)  # Add batch and channel dimensions\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "tedpfLuve2Fg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the new image you want to test\n",
        "file_path = '/content/drive/MyDrive/Signature/forged/NFI-08804004.png'\n",
        "\n",
        "# Preprocess the image\n",
        "processed_img = preprocess_image(file_path)\n",
        "\n",
        "# Predict using the trained model\n",
        "prediction = model.predict(processed_img)  # Get prediction probabilities\n",
        "predicted_class = np.argmax(prediction)  # Convert probabilities to class label (0 or 1)\n",
        "\n",
        "# Print the result\n",
        "if predicted_class == 1:\n",
        "    print(\"The signature is Genuine.\")\n",
        "else:\n",
        "    print(\"The signature is Forged.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4SrqkDqe4KM",
        "outputId": "a2800914-69e5-4ca4-fb7e-ced6b90ff635"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "The signature is Forged.\n"
          ]
        }
      ]
    }
  ]
}